from pyspark.sql import SparkSession

spark = SparkSession\
    .builder\
    .appName("SparkSession-read-minio") \
    .config("spark.executor.cores", "1") \
    .config("spark.executor.memory", "1g") \
    .config("spark.executor.instances", "2") \
    .getOrCreate()
spark


# spark.stop()


df = spark.read.csv("s3a://kevin/combined_financial_data_idx.csv", header=True, inferSchema=True).limit(100)


df.show(5)


df.printSchema()


df.write.parquet("kevin/test")





df.write \
    .format("parquet") \
    .mode("overwrite") \
    .saveAsTable("default.test_table_3")


spark.sql("SHOW TABLES").show()


spark.sql("SELECT * FROM test_table_3").show()


spark.stop()
